DONE

    Create a separate frame allocator for receive packets vs. send packets.

    The first half of the umem will have frames for packet sends, the second half will be frames for packet receives.

    It seems that the send and receive queue sizes both overlap, as well as send/complete

    So the reality is that we really only need 8k frames, if it is 4k per-queue.

    Updated and added asserts which check that actually both send and receive queue sizes must be num frames / 2.

    Verify the new frame allocators compile and work

    Had to double the frame allocators, since you can have worst case n in fill queue, and n in complete queue, so you actually need n*2 for receive, and same for send.

    Increase to 8 NIC queues and see that NEXT_MTU (max packet bytes) can be sent for one client.

TODO

    Mock 1000 clients with incrementing port numbers to see how many packets we can send before it blows up

    The different port numbers should scale RSS on the receive side

    ----------

    Now we need to start profiling. I need some way to have a test XDP receiver (linux) which will count how many packets are received per-second and display them

    It needs to be linux and xdp because we'll need to fake many connected clients (1000) and send many packets

    ----------









    -------------

    Implement rate limiting in XDP x requests per-y seconds keyed on IP address

    -------------

    Fix the connect token so we never send the user hash over un-encrypted channels

    This involves doing key exchange and switching over to more advanced crypto primitive

    Add these primitives to proton and then upgrade the code in protect to do the key exchange at the same time as processing the connect token

    -------------

    Implement ip2location in client backend

    -------------

    Implement the client ping near relay design

    -------------

    Implement requesting a route and sending packets across it

    -------------

    Double this route and implement multipath

    -------------
